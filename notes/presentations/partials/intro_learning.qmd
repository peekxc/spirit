## Learning with persistence 

There are many mappings from $\mathrm{dgm}$'s to function spaces (e.g. Hilbert spaces) 

<ul> 

- [Persistence Landscapes [@bubenik2020persistence]]{.fragment .fade-in fragment-index=1 style="text-align: left"}

</ul>

::: {.fragment .fade-in-then-out fragment-index=1 style="text-align: center"}

![](images/pers_landscape_def.png){width=40% fig-align="center"}

$$ \lambda(k, t) = \sup \{ h \geq 0 \mid \mathrm{rank}(H_p^{i-h} \to H_p^{i+h}) \geq k \} $$

:::


## Learning with persistence 

There are many mappings from $\mathrm{dgm}$'s to function spaces (e.g. Hilbert spaces) 

<ul> 

- Persistence Landscapes [@bubenik2020persistence] + Learning applications [@kim2020pllay]

</ul>

![](images/pers_landscape_app.png){width=40% fig-align="center"}

$$ \lambda(k, t) = \sup \{ h \geq 0 \mid \mathrm{rank}(H_p^{i-h} \to H_p^{i+h}) \geq k \} $$


## Learning with persistence 

There are many mappings from $\mathrm{dgm}$'s to function spaces (e.g. Hilbert spaces) 

<ul> 

- [Persistence Landscapes [@bubenik2020persistence] + Learning applications [@kim2020pllay]]{style="color: rgb(127,127,127);"}
- [Persistence Images [@adams2017persistence]]{.fragment .fade-in fragment-index=1 style="text-align: left"}

::: {.fragment .fade-in-then-out fragment-index=1 style="text-align: center"}

![](images/pers_image_def.png){height=50% fig-align="center"}

$$ \rho(f, \phi) = \sum\limits_{(i,j) \in \mathrm{dgm}} f(i,j) \phi(\lvert j - i \rvert)$$

:::
</ul>

## Learning with persistence 

There are many mappings from $\mathrm{dgm}$'s to function spaces (e.g. Hilbert spaces) 

<ul> 

- [Persistence Landscapes [@bubenik2020persistence] + Learning applications [@kim2020pllay]]{style="color: rgb(127,127,127);"}
- Persistence Images [@adams2017persistence] + Learning applications [@som2020pi]

<ul> 

![](images/pers_image_app.png){height=50% fig-align="center"}

$$ \rho(f, \phi) = \sum\limits_{(i,j) \in \mathrm{dgm}} f(i,j) \phi(\lvert j - i \rvert)$$

## Learning with persistence 

There are many mappings from $\mathrm{dgm}$'s to function spaces (e.g. Hilbert spaces) 

<ul> 

::: { style="color: rgb(127,127,127);"}
- Persistence Landscapes [@bubenik2020persistence] + Learning applications [@kim2020pllay] 
- Persistence Images [@adams2017persistence] + Learning applications [@som2020pi]
:::

::: {.fragment .fade-in}
- A few others...$^1$

![](images/vec1.png){width=80% height=100% fig-align="center"}

[See [@bubenik2020persistence] for an overview.]{.aside}
:::

</ul>

## Many goals in common...

:::: {.columns}
::: {.column width=40% layout-align="left" style="margin-left: 2em; margin-top: 1em;"}

- [Vectorize persistence information]{.fragment fragment-index=1}
- [Optimize persistence invariants]{.fragment fragment-index=2}
- [Leverage the stability of persistence]{.fragment fragment-index=3}
- [Connect to other areas of mathematics]{.fragment fragment-index=4}

:::

::: {.column width=40% layout-align="left"}
:::{.r-stack}

[![](images/pers_image.png)]{.fragment .fade-in-then-out fragment-index=1 width="300" height="300"}

[![](images/pers_landscape_app.png)]{.fragment .fade-in-then-out fragment-index=2 width="300" height="300"}

[![](animations/stability.gif)]{.fragment .fade-in-then-out fragment-index=3 width="400" height="300"}

[![](images/lsst.png)]{.fragment .fade-in fragment-index=4 width="375" height="375"}

:::
:::
::::

[__Can we achieve these goals without computing diagrams?__]{.fragment .r-fit-text style="text-align: center"}
